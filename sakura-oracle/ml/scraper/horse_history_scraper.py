"""
SAKURA ORACLE â€” é¦¬åˆ¥å…¨æˆ¦ç¸¾ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼

netkeibaã®é¦¬ãƒšãƒ¼ã‚¸ã‹ã‚‰å…¨æˆ¦ç¸¾ã‚’å–å¾—ã—ã€feature_engineering.pyã¨åŒç­‰ã®ç‰¹å¾´é‡ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚
features.csvã«éå»ãƒ‡ãƒ¼ã‚¿ãŒãªã„æœªçŸ¥é¦¬ã®ç‰¹å¾´é‡è£œå®Œã«ä½¿ç”¨ã™ã‚‹ã€‚

ä½¿ã„æ–¹:
    from ml.scraper.horse_history_scraper import build_features_from_history
    features = build_features_from_history("2024105678", target_date="20260301")
"""

import re
import sys
from datetime import datetime
from io import StringIO
from pathlib import Path

import numpy as np
import pandas as pd
from bs4 import BeautifulSoup

sys.path.insert(0, str(Path(__file__).resolve().parent.parent.parent))

from ml.scraper.race_scraper import safe_request
from ml.model.feature_engineering import (
    calc_speed_index,
    parse_time_to_seconds,
    parse_weight,
)


def _scrape_horse_history(horse_id: str) -> pd.DataFrame | None:
    """é¦¬ãƒšãƒ¼ã‚¸ã®æˆ¦ç¸¾ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ—ã™ã‚‹ã€‚

    Args:
        horse_id: netkeibaã®é¦¬IDï¼ˆ9-10æ¡ï¼‰

    Returns:
        æˆ¦ç¸¾DataFrame or Noneï¼ˆå–å¾—å¤±æ•—æ™‚ï¼‰
    """
    url = f"https://db.netkeiba.com/horse/result/{horse_id}/"
    content = safe_request(url)
    if content is None:
        return None

    soup = BeautifulSoup(content, "lxml")

    # æˆ¦ç¸¾ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ¤œå‡º
    table = soup.select_one("table.db_h_race_results")
    if table is None:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ˜ãƒƒãƒ€ã«ã€Œæ—¥ä»˜ã€ã€Œç€é †ã€ã‚’å«ã‚€ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ¤œç´¢
        for t in soup.select("table"):
            header = t.get_text()[:300]
            if "æ—¥ä»˜" in header and "ç€é †" in header:
                table = t
                break

    if table is None:
        return None

    try:
        df = pd.read_html(StringIO(str(table)), header=0)[0]
    except Exception:
        return None

    if df.empty:
        return None

    # ã‚«ãƒ©ãƒ åæ­£è¦åŒ–
    rename_map: dict[str, str] = {}
    for col in df.columns:
        s = str(col).strip().replace("\u3000", "").replace(" ", "")
        if s == "æ—¥ä»˜":
            rename_map[col] = "æ—¥ä»˜"
        elif s == "é–‹å‚¬":
            rename_map[col] = "é–‹å‚¬"
        elif s == "ãƒ¬ãƒ¼ã‚¹å":
            rename_map[col] = "ãƒ¬ãƒ¼ã‚¹å"
        elif s == "è·é›¢":
            rename_map[col] = "è·é›¢"
        elif s == "ç€é †":
            rename_map[col] = "ç€é †"
        elif s == "ã‚¿ã‚¤ãƒ ":
            rename_map[col] = "ã‚¿ã‚¤ãƒ "
        elif "ä¸Šã‚Š" in s or "ä¸ŠãŒã‚Š" in s or "å¾Œ3F" in s:
            rename_map[col] = "ä¸ŠãŒã‚Š3F"
        elif "é€šé" in s:
            rename_map[col] = "é€šéé †"
        elif "ç€å·®" in s:
            rename_map[col] = "ç€å·®"
        elif "é¦¬ä½“é‡" in s:
            rename_map[col] = "é¦¬ä½“é‡"
        elif s == "é ­æ•°":
            rename_map[col] = "é ­æ•°"
        elif s == "é¦¬å ´":
            rename_map[col] = "é¦¬å ´"

    if rename_map:
        df = df.rename(columns=rename_map)

    # ç€é †ã‚’æ•°å€¤åŒ–ï¼ˆé™¤å¤–ãƒ»ä¸­æ­¢ã‚’é™¤å¤–ï¼‰
    if "ç€é †" in df.columns:
        df["ç€é †"] = pd.to_numeric(df["ç€é †"], errors="coerce")
        df = df.dropna(subset=["ç€é †"]).copy()
        df["ç€é †"] = df["ç€é †"].astype(int)

    return df


def _parse_distance(dist_str: str) -> tuple[str, int]:
    """è·é›¢æ–‡å­—åˆ— 'èŠ1600' â†’ ('èŠ', 1600)ã€'ãƒ€1200' â†’ ('ãƒ€ãƒ¼ãƒˆ', 1200)"""
    if pd.isna(dist_str):
        return "", 0
    s = str(dist_str).strip()
    m = re.match(r"(èŠ|ãƒ€|éšœ)(\d+)", s)
    if m:
        surface = "èŠ" if m.group(1) == "èŠ" else "ãƒ€ãƒ¼ãƒˆ"
        return surface, int(m.group(2))
    return "", 0


def _parse_passing(val: str) -> float | None:
    """é€šéé †æ–‡å­—åˆ— '3-3-3-2' â†’ æœ€åˆã®æ•°å­—ï¼ˆã‚¹ã‚¿ãƒ¼ãƒˆä½ç½®ï¼‰"""
    if pd.isna(val):
        return None
    try:
        parts = str(val).strip().split("-")
        return float(parts[0])
    except (ValueError, IndexError):
        return None


def _parse_margin(val: str) -> float | None:
    """ç€å·®æ–‡å­—åˆ—ã‚’æ•°å€¤åŒ–ï¼ˆé¦¬èº«å˜ä½ï¼‰"""
    if pd.isna(val):
        return 0.0
    s = str(val).strip()
    if s in ("", "åŒç€"):
        return 0.0
    margin_map = {"ãƒãƒŠ": 0.05, "ã‚¢ã‚¿ãƒ": 0.1, "ã‚¯ãƒ“": 0.25}
    for key, num in margin_map.items():
        if key in s:
            return num
    try:
        s = s.replace("å¤§å·®", "10")
        # "1.1/2" â†’ 1.5
        match = re.match(r"(\d+)\.(\d)/(\d)", s)
        if match:
            whole = int(match.group(1))
            num = int(match.group(2))
            den = int(match.group(3))
            return whole + num / den
        # "1/2", "3/4"
        match = re.match(r"(\d+)/(\d+)", s)
        if match:
            return int(match.group(1)) / int(match.group(2))
        return float(s)
    except (ValueError, ZeroDivisionError):
        return None


def _extract_venue(kaisu_str: str) -> str:
    """é–‹å‚¬æ–‡å­—åˆ— '1é˜ªç¥' â†’ 'é˜ªç¥'ã€'3æ±äº¬' â†’ 'æ±äº¬'"""
    if pd.isna(kaisu_str):
        return ""
    s = str(kaisu_str).strip()
    # æ•°å­—éƒ¨åˆ†ã‚’é™¤å»
    venue = re.sub(r"\d+", "", s)
    return venue


def build_features_from_history(
    horse_id: str,
    target_date: str = "",
    horse_name: str = "",
) -> dict | None:
    """é¦¬ãƒšãƒ¼ã‚¸ã®å…¨æˆ¦ç¸¾ã‹ã‚‰ç‰¹å¾´é‡dictã‚’æ§‹ç¯‰ã™ã‚‹ã€‚

    Args:
        horse_id: netkeibaã®é¦¬ID
        target_date: å¯¾è±¡ãƒ¬ãƒ¼ã‚¹æ—¥ (YYYYMMDDå½¢å¼) â€” å‡ºèµ°é–“éš”è¨ˆç®—ç”¨
        horse_name: é¦¬åï¼ˆãƒ­ã‚°å‡ºåŠ›ç”¨ï¼‰

    Returns:
        ç‰¹å¾´é‡dictï¼ˆFEATURE_COLS_ALLã«å¯¾å¿œã™ã‚‹ã‚­ãƒ¼ã‚’æŒã¤ï¼‰or None
    """
    display_name = horse_name or horse_id
    hist = _scrape_horse_history(horse_id)
    if hist is None or hist.empty:
        print(f"    âŒ {display_name}: æˆ¦ç¸¾å–å¾—å¤±æ•—")
        return None

    # æ—¥ä»˜ã§ã‚½ãƒ¼ãƒˆï¼ˆå¤ã„é †ï¼‰
    if "æ—¥ä»˜" in hist.columns:
        hist["_date"] = pd.to_datetime(hist["æ—¥ä»˜"], errors="coerce")
        hist = hist.sort_values("_date").reset_index(drop=True)
    else:
        hist = hist.reset_index(drop=True)

    # å¯¾è±¡ãƒ¬ãƒ¼ã‚¹æ—¥ã‚ˆã‚Šå‰ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ä½¿ç”¨
    if target_date and "_date" in hist.columns:
        target_dt = pd.to_datetime(target_date, format="%Y%m%d", errors="coerce")
        if target_dt is not None:
            hist = hist[hist["_date"] < target_dt].copy()
            if hist.empty:
                print(f"    âš ï¸ {display_name}: å¯¾è±¡æ—¥ä»¥å‰ã®ãƒ¬ãƒ¼ã‚¹å±¥æ­´ãªã—")
                return None

    n_races = len(hist)
    print(f"    ğŸ“Š {display_name}: {n_races}æˆ¦ã®å±¥æ­´ã‚’å–å¾—")

    # === è·é›¢ãƒ»é¦¬å ´ãƒ‘ãƒ¼ã‚¹ ===
    if "è·é›¢" in hist.columns:
        parsed = hist["è·é›¢"].apply(_parse_distance)
        hist["_surface"] = parsed.apply(lambda x: x[0])
        hist["_distance"] = parsed.apply(lambda x: x[1])
    else:
        hist["_surface"] = ""
        hist["_distance"] = 0

    # === é–‹å‚¬å ´æ‰€ ===
    if "é–‹å‚¬" in hist.columns:
        hist["_venue"] = hist["é–‹å‚¬"].apply(_extract_venue)
    else:
        hist["_venue"] = ""

    # === é¦¬å ´çŠ¶æ…‹ï¼ˆgoingã‚«ãƒ©ãƒ ï¼‰===
    going_col = "é¦¬å ´" if "é¦¬å ´" in hist.columns else None

    # === ç€é †ï¼ˆæ—¢ã«æ•°å€¤åŒ–æ¸ˆã¿ï¼‰===
    finish = hist["ç€é †"]

    # === ã‚¿ã‚¤ãƒ  â†’ ç§’æ•° ===
    if "ã‚¿ã‚¤ãƒ " in hist.columns:
        hist["_time_sec"] = hist["ã‚¿ã‚¤ãƒ "].apply(parse_time_to_seconds)
    else:
        hist["_time_sec"] = np.nan

    # === ã‚¹ãƒ”ãƒ¼ãƒ‰æŒ‡æ•° ===
    def _calc_si(row: pd.Series) -> float | None:
        going = str(row.get(going_col, "è‰¯")) if going_col else "è‰¯"
        return calc_speed_index(row["_time_sec"], int(row["_distance"]), going)

    hist["_speed_index"] = hist.apply(_calc_si, axis=1)

    # === ä¸ŠãŒã‚Š3F ===
    if "ä¸ŠãŒã‚Š3F" in hist.columns:
        hist["_last3f"] = pd.to_numeric(hist["ä¸ŠãŒã‚Š3F"], errors="coerce")
    else:
        hist["_last3f"] = np.nan

    # === é€šéé † ===
    if "é€šéé †" in hist.columns:
        hist["_start_pos"] = hist["é€šéé †"].apply(_parse_passing)
    else:
        hist["_start_pos"] = np.nan

    # === ç€å·® ===
    if "ç€å·®" in hist.columns:
        hist["_margin"] = hist["ç€å·®"].apply(_parse_margin)
    else:
        hist["_margin"] = np.nan

    # === é¦¬ä½“é‡ ===
    if "é¦¬ä½“é‡" in hist.columns:
        weight_data = hist["é¦¬ä½“é‡"].apply(parse_weight)
        hist["_weight"] = weight_data.apply(lambda x: x[0])
        hist["_weight_diff"] = weight_data.apply(lambda x: x[1])
    else:
        hist["_weight"] = np.nan
        hist["_weight_diff"] = np.nan

    # === ç‰¹å¾´é‡æ§‹ç¯‰ ===
    features: dict = {}

    # total_runs: éå»èµ°æ•°
    features["total_runs"] = n_races

    # show_rate: 3ç€ä»¥å†…ç‡
    show_count = (finish <= 3).sum()
    features["show_rate"] = show_count / n_races if n_races > 0 else 0

    # last1_finish: ç›´è¿‘ã®ç€é †
    features["last1_finish"] = float(finish.iloc[-1])

    # speed_index: ç›´è¿‘ã®ã‚¹ãƒ”ãƒ¼ãƒ‰æŒ‡æ•°
    valid_si = hist["_speed_index"].dropna()
    features["speed_index"] = float(valid_si.iloc[-1]) if len(valid_si) > 0 else np.nan

    # last1_speed: 1èµ°å‰ã®ã‚¹ãƒ”ãƒ¼ãƒ‰æŒ‡æ•°
    if len(valid_si) >= 1:
        features["last1_speed"] = float(valid_si.iloc[-1])
    else:
        features["last1_speed"] = np.nan

    # ä¸ŠãŒã‚Š3F çµ±è¨ˆ
    valid_3f = hist["_last3f"].dropna()
    features["avg_last3f"] = float(valid_3f.mean()) if len(valid_3f) > 0 else np.nan
    features["best_last3f"] = float(valid_3f.min()) if len(valid_3f) > 0 else np.nan
    features["last1_last3f"] = float(valid_3f.iloc[-1]) if len(valid_3f) > 0 else np.nan
    features["last2_last3f"] = float(valid_3f.iloc[-2]) if len(valid_3f) >= 2 else np.nan

    # é˜ªç¥å®Ÿç¸¾
    features["hanshin_runs"] = int((hist["_venue"] == "é˜ªç¥").sum())

    # ç›´è¿‘ã®é€šéé †ï¼ˆã‚¹ã‚¿ãƒ¼ãƒˆä½ç½®ï¼‰
    valid_sp = hist["_start_pos"].dropna()
    features["last1_start_pos"] = float(valid_sp.iloc[-1]) if len(valid_sp) > 0 else np.nan

    # ç›´è¿‘ã®ç€å·®
    valid_margin = hist["_margin"].dropna()
    features["last1_margin"] = float(valid_margin.iloc[-1]) if len(valid_margin) > 0 else np.nan

    # ãƒšãƒ¼ã‚¹åå·®å€¤
    # å‰åŠã‚¿ã‚¤ãƒ  = ã‚¿ã‚¤ãƒ  - ä¸ŠãŒã‚Š3Fã€ãƒãƒ­ãƒ³æ•° = (è·é›¢-600)/200
    if "ä¸ŠãŒã‚Š3F" in hist.columns and "ã‚¿ã‚¤ãƒ " in hist.columns:
        hist["_front_half"] = hist["_time_sec"] - hist["_last3f"]
        hist["_furlongs"] = (hist["_distance"] - 600) / 200
        hist["_pace_per_f"] = hist["_front_half"] / hist["_furlongs"].replace(0, np.nan)
        valid_pace = hist["_pace_per_f"].dropna()
        if len(valid_pace) > 1:
            # åå·®å€¤åŒ–ï¼ˆå¹³å‡=50ã€æ¨™æº–åå·®=10ï¼‰
            mean_p = valid_pace.mean()
            std_p = valid_pace.std()
            if std_p > 0:
                last_pace = float(valid_pace.iloc[-1])
                features["pace_deviation"] = (last_pace - mean_p) / std_p * 10 + 50
                if len(valid_pace) >= 2:
                    prev_pace = float(valid_pace.iloc[-2])
                    features["last1_pace_deviation"] = (prev_pace - mean_p) / std_p * 10 + 50
                else:
                    features["last1_pace_deviation"] = features["pace_deviation"]
            else:
                features["pace_deviation"] = 50.0
                features["last1_pace_deviation"] = 50.0
        elif len(valid_pace) == 1:
            features["pace_deviation"] = 50.0
            features["last1_pace_deviation"] = 50.0
        else:
            features["pace_deviation"] = np.nan
            features["last1_pace_deviation"] = np.nan
    else:
        features["pace_deviation"] = np.nan
        features["last1_pace_deviation"] = np.nan

    # å‡ºèµ°é–“éš”ï¼ˆrest_weeksï¼‰: å¯¾è±¡ãƒ¬ãƒ¼ã‚¹æ—¥ - ç›´è¿‘ãƒ¬ãƒ¼ã‚¹æ—¥
    if target_date and "_date" in hist.columns:
        target_dt = pd.to_datetime(target_date, format="%Y%m%d", errors="coerce")
        last_date = hist["_date"].iloc[-1]
        if pd.notna(target_dt) and pd.notna(last_date):
            features["rest_weeks"] = (target_dt - last_date).days / 7.0

    # é¦¬ä½“é‡
    valid_w = hist["_weight"].dropna()
    valid_wd = hist["_weight_diff"].dropna()
    features["weight"] = float(valid_w.iloc[-1]) if len(valid_w) > 0 else np.nan
    features["weight_diff"] = float(valid_wd.iloc[-1]) if len(valid_wd) > 0 else np.nan

    return features


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆç”¨: å¼•æ•°ã«horse_idã‚’æŒ‡å®š
    if len(sys.argv) < 2:
        print("ä½¿ã„æ–¹: py ml/scraper/horse_history_scraper.py <horse_id> [target_date]")
        print("ä¾‹: py ml/scraper/horse_history_scraper.py 2022105678 20260301")
        sys.exit(1)

    hid = sys.argv[1]
    t_date = sys.argv[2] if len(sys.argv) > 2 else ""
    result = build_features_from_history(hid, target_date=t_date)
    if result:
        print("\n--- æ§‹ç¯‰ã•ã‚ŒãŸç‰¹å¾´é‡ ---")
        for k, v in sorted(result.items()):
            print(f"  {k}: {v}")
    else:
        print("ç‰¹å¾´é‡æ§‹ç¯‰å¤±æ•—")
