"""
SAKURA ORACLE â€” çµ„åˆã›ã‚ªãƒƒã‚ºã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼

netkeibaã®JSON APIã‹ã‚‰é¦¬é€£ãƒ»ãƒ¯ã‚¤ãƒ‰ãƒ»é¦¬å˜ãƒ»ä¸‰é€£è¤‡ãƒ»ä¸‰é€£å˜ã®ã‚ªãƒƒã‚ºã‚’å–å¾—ã™ã‚‹ã€‚

ä½¿ã„æ–¹:
    PYTHONIOENCODING=utf-8 py ml/scraper/odds_scraper.py 202609010411
"""

import pickle
import re
import sys
import time
import random
from pathlib import Path

import requests
import urllib3
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

sys.path.insert(0, str(Path(__file__).resolve().parent.parent.parent))

from ml.scraper.config import (
    HEADERS, CACHE_DIR,
    REQUEST_TIMEOUT, MAX_RETRIES, MIN_WAIT, MAX_WAIT, BACKOFF_BASE,
)


# APIã®ã‚ªãƒƒã‚ºã‚¿ã‚¤ãƒ—ç•ªå· â†’ é¦¬åˆ¸å
ODDS_TYPES: dict[str, str] = {
    "4": "é¦¬é€£",
    "5": "ãƒ¯ã‚¤ãƒ‰",
    "6": "é¦¬å˜",
    "7": "ä¸‰é€£è¤‡",
    "8": "ä¸‰é€£å˜",
}

# é¦¬åˆ¸ã‚¿ã‚¤ãƒ—ã”ã¨ã®ã‚­ãƒ¼æ¡æ•°ï¼ˆ2æ¡Ã—é ­æ•°ï¼‰
KEY_DIGITS: dict[str, int] = {
    "é¦¬é€£": 4,    # "0102" â†’ [1, 2]
    "ãƒ¯ã‚¤ãƒ‰": 4,
    "é¦¬å˜": 4,
    "ä¸‰é€£è¤‡": 6,  # "010203" â†’ [1, 2, 3]
    "ä¸‰é€£å˜": 6,
}


def _polite_sleep() -> None:
    """netkeibaç”¨ã®ç¤¼å„€æ­£ã—ã„å¾…æ©Ÿï¼ˆ3-7ç§’ãƒ©ãƒ³ãƒ€ãƒ ï¼‰"""
    time.sleep(random.uniform(MIN_WAIT, MAX_WAIT))


def _parse_key_to_horses(key: str, bet_type: str) -> list[int]:
    """APIã®ã‚­ãƒ¼æ–‡å­—åˆ—ã‹ã‚‰é¦¬ç•ªãƒªã‚¹ãƒˆã‚’å–å¾—ã™ã‚‹ã€‚

    "0102" â†’ [1, 2]
    "010203" â†’ [1, 2, 3]
    """
    expected_len = KEY_DIGITS.get(bet_type, 4)
    if len(key) != expected_len:
        return []

    horses: list[int] = []
    for i in range(0, len(key), 2):
        num_str = key[i:i+2]
        try:
            num = int(num_str)
            if 1 <= num <= 18:
                horses.append(num)
        except ValueError:
            return []
    return horses


def _fetch_odds_api(race_id: str, odds_type: str) -> dict | None:
    """netkeibaã®ã‚ªãƒƒã‚ºAPIã‚’å‘¼ã³å‡ºã™ã€‚

    Args:
        race_id: netkeibaã®race_idï¼ˆ12æ¡ï¼‰
        odds_type: ã‚ªãƒƒã‚ºã‚¿ã‚¤ãƒ—ç•ªå·ï¼ˆ"4"=é¦¬é€£, "5"=ãƒ¯ã‚¤ãƒ‰, ...ï¼‰

    Returns:
        APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®JSONãƒ‡ãƒ¼ã‚¿ or None
    """
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
    cache_key = f"odds_api_{race_id}_{odds_type}"
    cache_file = CACHE_DIR / f"{cache_key}.pkl"

    if cache_file.exists():
        with open(cache_file, "rb") as f:
            return pickle.load(f)

    url = "https://race.netkeiba.com/api/api_get_jra_odds.html"
    params = {
        "race_id": race_id,
        "type": odds_type,
        "action": "update",
    }
    # APIãƒªã‚¯ã‚¨ã‚¹ãƒˆç”¨ã®ãƒ˜ãƒƒãƒ€ãƒ¼ï¼ˆReferer, X-Requested-Withè¿½åŠ ï¼‰
    api_headers = {
        **HEADERS,
        "Referer": f"https://race.netkeiba.com/odds/index.html?race_id={race_id}&type=b{odds_type}",
        "X-Requested-With": "XMLHttpRequest",
    }

    for attempt in range(MAX_RETRIES):
        try:
            _polite_sleep()
            r = requests.get(
                url, headers=api_headers, params=params,
                timeout=REQUEST_TIMEOUT, verify=False,
            )

            if r.status_code == 400:
                backoff = BACKOFF_BASE * (attempt + 1)
                print(f"  âš ï¸ 400ã‚¨ãƒ©ãƒ¼ã€‚{backoff}ç§’å¾…æ©Ÿ...")
                time.sleep(backoff)
                continue
            if r.status_code == 404:
                print(f"  âš ï¸ 404: APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ")
                return None

            r.raise_for_status()
            data = r.json()

            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜
            with open(cache_file, "wb") as f:
                pickle.dump(data, f)

            return data

        except requests.RequestException as e:
            print(f"  ãƒªãƒˆãƒ©ã‚¤ {attempt + 1}/{MAX_RETRIES}: {e}")
            time.sleep(30)
        except ValueError as e:
            print(f"  JSONè§£æå¤±æ•—: {e}")
            return None

    print(f"  âŒ APIå–å¾—å¤±æ•—: type={odds_type}")
    return None


def _parse_api_odds(api_data: dict, odds_type: str, bet_type: str) -> list[dict]:
    """APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ã‚ªãƒƒã‚ºãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã™ã‚‹ã€‚

    APIã®å¿œç­”å½¢å¼:
        {"status": "middle", "data": {"odds": {"4": {"0102": ["472.9", "", "69"], ...}}}}

    ãƒ¯ã‚¤ãƒ‰ã®å ´åˆ:
        {"0102": ["112.4", "116.0", "71"]}  â†’ [ä¸‹é™, ä¸Šé™, äººæ°—é †] â†’ å¹³å‡å€¤ã‚’ä½¿ç”¨

    Returns:
        [{"type": "é¦¬é€£", "horses": [1, 2], "odds": 472.9}, ...]
    """
    odds_dict = api_data.get("data", {}).get("odds", {}).get(odds_type, {})
    if not odds_dict:
        return []

    results: list[dict] = []

    for key, values in odds_dict.items():
        if not isinstance(values, list) or len(values) < 1:
            continue

        # é¦¬ç•ªã‚’è§£æ
        horses = _parse_key_to_horses(key, bet_type)
        if not horses:
            continue

        # ã‚ªãƒƒã‚ºå€¤ã‚’è§£æ
        try:
            if bet_type == "ãƒ¯ã‚¤ãƒ‰" and len(values) >= 2 and values[1]:
                # ãƒ¯ã‚¤ãƒ‰ã¯ãƒ¬ãƒ³ã‚¸è¡¨è¨˜ â†’ å¹³å‡å€¤
                low = float(values[0])
                high = float(values[1])
                odds = (low + high) / 2.0
            else:
                odds = float(values[0])
        except (ValueError, TypeError, IndexError):
            continue

        if odds <= 0:
            continue

        results.append({
            "type": bet_type,
            "horses": horses,
            "odds": round(odds, 1),
        })

    return results


def scrape_combo_odds(race_id: str) -> list[dict]:
    """å…¨é¦¬åˆ¸ã‚¿ã‚¤ãƒ—ã®ã‚ªãƒƒã‚ºã‚’ä¸€æ‹¬å–å¾—ã™ã‚‹ã€‚

    netkeibaã®JSON APIã‚’ä½¿ç”¨ã—ã¦ã‚ªãƒƒã‚ºãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹ã€‚

    Args:
        race_id: netkeibaã®race_idï¼ˆ12æ¡ï¼‰

    Returns:
        [{"type": "é¦¬é€£", "horses": [3, 12], "odds": 201.1}, ...]
        combo_ev.py ã® _load_excel_odds() ã¨åŒã˜å‡ºåŠ›å½¢å¼ã€‚
    """
    print(f"\n--- çµ„åˆã›ã‚ªãƒƒã‚ºå–å¾— (race_id={race_id}) ---")
    all_results: list[dict] = []

    for odds_type, bet_type in ODDS_TYPES.items():
        print(f"  ğŸ“Š {bet_type} (type={odds_type}) å–å¾—ä¸­...")

        api_data = _fetch_odds_api(race_id, odds_type)
        if api_data is None:
            print(f"     â†’ å–å¾—å¤±æ•—")
            continue

        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèª
        status = api_data.get("status", "")
        if status == "nodata":
            print(f"     â†’ ã‚ªãƒƒã‚ºæœªå…¬é–‹ï¼ˆnodataï¼‰")
            continue

        results = _parse_api_odds(api_data, odds_type, bet_type)

        print(f"     â†’ {len(results)}ä»¶")
        all_results.extend(results)

    print(f"\n  ã‚ªãƒƒã‚ºå–å¾—åˆè¨ˆ: {len(all_results)}ä»¶")
    return all_results


# ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã® comboKey ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹
TYPE_TO_PREFIX: dict[str, str] = {
    "é¦¬é€£": "quinella",
    "ãƒ¯ã‚¤ãƒ‰": "wide",
    "ä¸‰é€£è¤‡": "trio",
}


def to_combo_odds_map(odds_list: list[dict]) -> dict[str, float]:
    """ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°çµæœã‚’comboKeyâ†’oddsãƒãƒƒãƒ—ã«å¤‰æ›ï¼ˆãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ç”¨ï¼‰ã€‚

    é¦¬å˜/ä¸‰é€£å˜ã¯ãƒ•ãƒ­ãƒ³ãƒˆã®BOX/è»¸æµã—ã§æœªä½¿ç”¨ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã€‚

    Args:
        odds_list: scrape_combo_odds() ã®æˆ»ã‚Šå€¤
            [{"type": "é¦¬é€£", "horses": [5, 12], "odds": 10.6}, ...]

    Returns:
        {"quinella-5-12": 10.6, "wide-5-12": 114.2, "trio-5-9-12": 1858.3, ...}
    """
    result: dict[str, float] = {}
    for entry in odds_list:
        prefix = TYPE_TO_PREFIX.get(entry["type"])
        if prefix is None:
            # é¦¬å˜ãƒ»ä¸‰é€£å˜ã¯ãƒ•ãƒ­ãƒ³ãƒˆã§æœªä½¿ç”¨ â†’ ã‚¹ã‚­ãƒƒãƒ—
            continue
        # é¦¬ç•ªã‚’ã‚½ãƒ¼ãƒˆã—ã¦ã‚­ãƒ¼ç”Ÿæˆï¼ˆãƒ•ãƒ­ãƒ³ãƒˆã¨åŒã˜å½¢å¼ï¼‰
        nums = sorted(entry["horses"])
        key = f"{prefix}-{'-'.join(str(n) for n in nums)}"
        result[key] = entry["odds"]
    return result


def main() -> None:
    """CLI ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆã€‚"""
    if len(sys.argv) < 2:
        print("ä½¿ã„æ–¹: PYTHONIOENCODING=utf-8 py ml/scraper/odds_scraper.py <race_id>")
        print()
        print("ä¾‹:")
        print("  py ml/scraper/odds_scraper.py 202609010411")
        sys.exit(1)

    race_id = sys.argv[1]
    results = scrape_combo_odds(race_id)

    if results:
        # é¦¬åˆ¸ã‚¿ã‚¤ãƒ—åˆ¥ã®é›†è¨ˆ
        type_counts: dict[str, int] = {}
        for entry in results:
            type_counts[entry["type"]] = type_counts.get(entry["type"], 0) + 1
        print(f"\n  ğŸ“‹ é¦¬åˆ¸ã‚¿ã‚¤ãƒ—åˆ¥:")
        for t, c in type_counts.items():
            print(f"    {t}: {c}ä»¶")

        print(f"\n  ğŸ‡ å–å¾—çµæœã‚µãƒ³ãƒ—ãƒ«ï¼ˆå…ˆé ­10ä»¶ï¼‰:")
        print(f"  {'åˆ¸ç¨®':>6} {'çµ„åˆã›':>12} {'ã‚ªãƒƒã‚º':>8}")
        print("  " + "-" * 30)
        for entry in results[:10]:
            targets = "-".join(str(h) for h in entry["horses"])
            print(f"  {entry['type']:>6} {targets:>12} {entry['odds']:>8.1f}")
        print(f"\n  åˆè¨ˆ: {len(results)}ä»¶")
    else:
        print("\n  âš ï¸ ã‚ªãƒƒã‚ºã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
        print("  åŸå› å€™è£œ:")
        print("    - ãƒ¬ãƒ¼ã‚¹ãŒæœªç™ºèµ°ã§ã‚ªãƒƒã‚ºæœªå…¬é–‹")
        print("    - race_id ãŒä¸æ­£")


if __name__ == "__main__":
    main()
